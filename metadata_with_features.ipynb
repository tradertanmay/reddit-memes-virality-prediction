{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install fer\n",
        "!pip install easyocr\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "ha2dkfd4fspe0ILZgWkRlu",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "QrA_bPa8BUc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "new_directory = \"/data/notebook_files/Reddit_Project\"\n",
        "os.chdir(new_directory)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "F60NlQMrfBHeQXBuIq3eUQ",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "Wxh11RwcBUc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from fer import FER\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "zvixurulnlgr5z27sPndIr",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "x439MDPOBUc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from memes_text_image import (\n",
        "    process_images3, process_dataframe, classify_sentiment,\n",
        "    determine_object_count,  map_to_category,  categorize_time, detect_objects_and_emotions,\n",
        "    extract_text_from_image,classify_category, normalize_upvotes )"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "zHdNEXarO5NT8Ul9MzKk3W",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "egxqVXOKBUc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_no_duplicates =pd.read_csv('/data/notebook_files/Reddit_Project/memes_metadata.csv')\n",
        "process_images3(df_no_duplicates, \"/data/notebook_files/Further_Process/FinalDataset/Dataset\", \"output_csv\")\n",
        "output101 = pd.read_csv('/data/notebook_files/Reddit_Project/output_csv')"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "fy0GBV71CbHPAqA1lkBjwI",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "h_YMlztVBUc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_folder = '/data/notebook_files/Further_Process/FinalDataset/Dataset'\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "emotion_model = FER()\n",
        "output101[['Detected Objects', 'Facial Expression']] = output101['Filename'].apply(\n",
        "    lambda filename: pd.Series(detect_objects_and_emotions(model,emotion_model,os.path.join(new_folder, filename)))\n",
        ")\n",
        "output101_with_text = process_dataframe(output101, new_folder)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "snVWyf2L5RhcTavobcj6tU",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "s2EHCSWDBUc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output101_with_text['object_expr_ind'] = output101_with_text['Facial Expression'].apply(lambda x: 0 if pd.isna(x) or x == '' or x.isspace() else 1)\n",
        "output101_with_text['Objects_ind'] = output101_with_text['Detected Objects'].apply(lambda x: 0 if pd.isna(x) or x == '' or x.isspace() else 1)\n",
        "output101_with_text['object_count'] = output101_with_text['Detected Objects'].apply(determine_object_count)\n",
        "output101_with_text = pd.get_dummies(output101_with_text, columns=['object_count'], prefix='object_count')\n",
        "output101_with_text['do_category'] = output101_with_text['Detected Objects'].apply(map_to_category)\n",
        "one_hot_encoded = pd.get_dummies(output101_with_text['do_category'], prefix='do_category')\n",
        "output101_with_text = pd.concat([output101_with_text, one_hot_encoded], axis=1)\n",
        "# Replace missing values in 'Facial Expression' with 'unknown'\n",
        "output101_with_text['Facial Expression'].fillna('unknown', inplace=True)\n",
        "output101_with_text = pd.get_dummies(output101_with_text, columns=['Facial Expression'], prefix='Facial_Expression')"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "6gcsLlu30ViQJlvPS68NSN",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "-9Iv0VH8BUc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_analyzer = pipeline('sentiment-analysis')\n",
        "output101_with_text['sentiment'] = output101_with_text['Extracted_Text'].apply(classify_sentiment)\n",
        "output101_with_text = pd.get_dummies(output101_with_text, columns=['sentiment'], prefix='meme_text_sentiment')"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "XnU9w8YvOifciAxK6iGsNB",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "Z92OahSqBUc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output101_with_text['UTC'] = output101_with_text['UTC'].apply(lambda x: datetime.utcfromtimestamp(x))\n",
        "output101_with_text['Time'] = output101_with_text['UTC'].apply(categorize_time)\n",
        "output101_with_text = pd.get_dummies(output101_with_text, columns=['Time'], prefix='Time')"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "Zw4rpzopIY6edcxEJJwxsB",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "2IKQdfi7BUc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cta_words = ['Comment',  'post', 'View', 'Reply', 'Posted', 'Follow', 'Share',  'Share Save']\n",
        "output101_with_text['call_to_action_ind'] = output101_with_text['Extracted_Text'].apply(lambda text: 1 if text and any(word.lower() in str(text).lower() for word in cta_words) else 0)\n",
        "output101_with_text['submission_text_ind'] = output101_with_text['Submission Text'].notnull().astype(int)\n",
        "output101_with_text['NSFW_ind'] = output101_with_text['NSFW'].astype(int)\n",
        "output101_with_text['title_word_count'] = output101_with_text['Title'].str.split().apply(len)\n"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "xgNBSoXPZsDhJRJzn0ixMh",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "8AlAvm3IBUc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_classifier = pipeline(\"sentiment-analysis\")\n",
        "output101_with_text['title_sentiment'] = output101_with_text['Title'].apply(classify_category)\n",
        "category_one_hot = pd.get_dummies(output101_with_text['title_sentiment'], prefix='title_sentiment')\n",
        "output101_with_text = pd.concat([output101_with_text, category_one_hot], axis=1)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "pyUk3Y7xyzqKIrJa4oka11",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "zHt90wY_BUc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output101_with_text['Height/Width Ratio'] = output101_with_text['Thumbnail Height'] / output101_with_text['Thumbnail Width']\n",
        "\n",
        "# Creating a new column for the product of Thumbnail Width and Thumbnail Height\n",
        "output101_with_text['Width*Height Product'] = output101_with_text['Thumbnail Width'] * output101_with_text['Thumbnail Height']"
      ],
      "metadata": {
        "id": "OfqJ-nPaBXMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_ventiles = 20\n",
        "ventile_labels = [i  for i in range(1, num_ventiles + 1)]\n",
        "\n",
        
        "if isinstance(output101_with_text, pd.DataFrame):\n",
        "    output101_with_text = output101_with_text.groupby('Subreddit').apply(normalize_upvotes)\n",
        "    output101_with_text['Ventile'] = pd.qcut(data['Normalized_Upvotes'], q=num_ventiles, labels=ventile_labels, duplicates='drop')\n",
        "else:\n",
        "    print(\"Error: 'data' is not a DataFrame.\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "YwofsnKBupqi7g8EhS2BgY",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "HDjGZ_V7BUc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output101_with_text.to_csv(metadata_with_features.csv)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "oQWoGwGVioLObOqcfJV9Oq",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "04gmVnN-BUc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "condition_1 = (output101_with_text['Ventile'] == 20) | (output101_with_text['Ventile'] == 1)\n",
        "filtered_data_11 = output101_with_text[condition_1]"
      ],
      "metadata": {
        "id": "ZjrLRqyICd54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output101_with_text['viral_q'] = output101_with_text['Ventile'].apply(lambda x: 1 if  x== 20 else 0)\n"
      ],
      "metadata": {
        "id": "hf9CeTpTClcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output101_with_text.to_csv('complete_viral_dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "x7DGP_MrCopM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python"
    },
    "datalore": {
      "computation_mode": "JUPYTER",
      "package_manager": "pip",
      "base_environment": "minimal",
      "packages": [],
      "report_row_ids": [],
      "version": 3
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
